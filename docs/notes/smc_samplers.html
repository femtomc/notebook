<html>
<head>
<title>McCoy R. Becker</title>
<meta name="robots" content="no index, nofollow" charset="utf-8">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="../assets/js/mathjax3-tex-svg.js">
</script>
<link rel="stylesheet"
      href="../assets/js/highlight/styles/default.min.css">
<script src="../assets/js/highlight/highlight.min.js"></script>
<script src="../assets/js/highlight/languages/haskell.min.js"></script>
<style>
@import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
@import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
@import url(https://fonts.googleapis.com/css2?family=PT+Serif&display=swap);
</style>
<link rel="stylesheet" type="text/css" href="../assets/css/fonts.css"/>
<link rel="stylesheet" type="text/css" href="../assets/css/style.css"/>
</head>
<body>
<div id="doc"><h1>Notes on sequential Monte Carlo</h1><p>There is a critical (and still <i>highly relevant</i>) paper on sequential Monte Carlo (SMC) samplers which deserves a read from all those interesting in probabilistic modeling and approximate inference.</p><p>The paper is <a href="https://www.stats.ox.ac.uk/~doucet/delmoral_doucet_jasra_sequentialmontecarlosamplersJRSSB.pdf">Sequential Monte Carlo samplers</a> by Pierre Del Moral, Arnaud Doucet, and Ajay Jasra (DMDJ) - whose contributions include laying the conceptual bricks for modern variants of SMC by carefully discussing a methodology to sample sequentially from a sequence of probability distributions defined on the same space.</p><p>In this note, I’ll be working through the paper - elaborating where I may, and deferring to other material as required.</p><h2>Background</h2><p>Sampling from probability distributions is a commonly desired operation in probabilistic modeling and inference. Especially in the latter case, direct sampling can sometimes be intractable - either because the distribution in question may be defined indirectly through marginalization of an existing density (which is often intractable, although sometimes not) or because <a href="https://web.mit.edu/urban_or_book/www/book/chapter7/7.1.3.html">existing methods</a> do not apply to densities which lack an analytic CDF.</p><p>Practitioners have constructed clever approximation techniques to get around these limitations, including Monte Carlo methods - algorithms which internally use randomness to approximately perform optimization, numerical integration, and sampling from target probability distributions.</p><p>Sequential Monte Carlo (SMC) is one such method with a unique set of computational trade offs compared to other approximate inference techniques. One way of understanding sequential Monte Carlo steps is as incremental importance sampling, where particle populations are evolved and re-weighted at each step - including the effects of conditioning on new observations. Formally, SMC allows us to think about the transition:</p><p><mathjax>\begin{equation}P(\vec{z}_t | \vec{x_t}) \rightarrow P(\vec{z}_{t + 1} | \vec{x}_{t + 1})\end{equation}</mathjax></p><p>if I have a particle representation of the LHS, I can perform an SMC update to target the RHS.</p><h2>Comparison to Markov chain Monte Carlo</h2><p>As part of the motivation, (DMDJ) discuss a number of computational comparisons between SMC samplers and Markov chain Monte Carlo (MCMC) samplers.</p><div class="itemize"><ol><li>For batch observations <mathjax>$y_1, ..., y_n$</mathjax>, MCMC sampling require complete likelihood evaluation at each step. This must include all observations, which may be prohibitively expensive. Instead, it may be computationally beneficial to evaluate likelihoods on partial sets of observations in sequence.</li><li>For computational reasons, it may be useful to sample <i>sequentially</i> from a series of distributions, beginning with an easy-to-sample distribution <mathjax>$\pi_1$</mathjax> and ending with the distribution of interest <mathjax>$\pi_p$</mathjax>.</li></ol></div><h2>A simple working example</h2><p>One easy way to understand why this technique is useful is to imagine that a you want to update a distribution in light of new evidence in an online fashion (one new observation every so often).</p><figure><p><img src="images/dot_g9589.svg"/></p><figcaption>Graphical model representation of an unrolled hidden Markov model.</figcaption></figure><p>Traditionally, SMC algorithms were developed to solve dynamical systems filtering problems. Let’s look at the decomposition of the joint from the model displayed above.</p><p><mathjax>\begin{equation}P(X_0, X_1, X_2, Y_0, Y_1, Y_2) = P(X_0) \prod_{i = 0} P(X_{i + 1} | X_i)P(Y_i | X_i)\end{equation}</mathjax></p><p>Now, from this joint, we could use SMC to compute approximations to the sequence of distributions <mathjax>$P(X_0 | Y_0)$</mathjax>, <mathjax>$P(X_0, X_1| Y_0, Y_1)$</mathjax>, <mathjax>$P(X_0, X_1, X_2| Y_0, Y_1, Y_2)$</mathjax> in turn.</p><p><mathjax>\begin{equation}\begin{aligned}
T_0^i &amp;\sim Q(T_0; Y_0), \hat{w}_0^i = \frac{P(T_0^i, Y_0)}{Q(T_0^i)}\\
T_t^i &amp;\sim Q(T_{t - 1}^i; Y_t), \hat{w}_t^i = \frac{P(T_t^i,..., T_0^i, Y_t,...,Y_0)}{Q(T_t^i)}
\end{aligned}\end{equation}</mathjax></p><p>where <mathjax>$T_t^i$</mathjax> stands for the <i>i</i>-th sample representation of the latent space at time step <mathjax>$t$</mathjax>. The “importance weight” (from importance sampling) of particle <mathjax>$i$</mathjax> at time step <mathjax>$t$</mathjax> is <mathjax>$\hat{w}_t$</mathjax> is the pointwise evaluation of the <a href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem#Radon%E2%80%93Nikodym_derivative">Radon-Nikodym derivative</a> of the measure associated with the model density <mathjax>$P$</mathjax> and the measure associated with the proposal density <mathjax>$Q$</mathjax>.</p><div class="note">I discuss Radon-Nikodym derivatives in <span class="xlink"><xlink>notes/math_is.html</xlink><a class="xlink" href="../notes/math_is.html">The mathematical foundations of importance sampling</a></span>, but also see the Wikipedia page linked above.</div><p>From the importance weights, it’s easy to spot the “absolute continuity” condition: <mathjax>$Q$</mathjax> can’t assign zero probability to a primitive set that <mathjax>$P$</mathjax> assigns non-zero probability.</p><p>This presentation is originally from <a href="https://www.stats.ox.ac.uk/~doucet/doucet_defreitas_gordon_smcbookintro.pdf">Doucet, de Freitas, and Gordon</a>. This presentation should also be praised for treatment of Monte Carlo sampling in general (and in computational comparison with techniques like numerical integration).</p><h2>Sequential importance sampling</h2><h2>Sequential importance resampling</h2><h2>Conditional SMC</h2><h2>Resample-move SMC</h2><p>In this section, I’d like to discuss a modification to the SMC framework discussed above which introduces MCMC steps in between SMC update steps. The resultant algorithm class is profoundly interesting. I discuss this class in more depth in <span class="xlink"><xlink>notes/unreasonable_smc.html</xlink><a class="xlink" href="../notes/unreasonable_smc.html">The unreasonable effectiveness of rejuvenation move SMC</a></span>.</p><h2>Relevant works</h2><p>There are quite a few relevant works which have contributed to my own presentation here:</p><div class="itemize"><ol><li><a href="https://www.stats.ox.ac.uk/~doucet/doucet_defreitas_gordon_smcbookintro.pdf">Doucet, de Freitas, and Gordon, 2001</a></li><li><a href="http://www.mathcs.emory.edu/~whalen/Papers/BNs/MonteCarlo-DBNs.pdf">Gilks and Berzuini, 2001</a></li><li><a href="https://www.stats.ox.ac.uk/~doucet/delmoral_doucet_jasra_sequentialmontecarlosamplersJRSSB.pdf">Del Moral, Doucet, and Jasra, 2006</a></li><li><a href="https://www.stats.ox.ac.uk/~doucet/doucet_johansen_tutorialPF2011.pdf">Doucet and Johansen, 2008</a></li></ol></div></div>
</script>
</body>
<script>hljs.highlightAll();</script>
</html>